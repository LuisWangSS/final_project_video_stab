{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc62idQUCwnL"
      },
      "source": [
        "# Colab：Deep Online Fused Video Stabilization 推理与指标\n",
        "\n",
        "说明：本 notebook 直接在 Colab GPU 上运行，完成仓库克隆、依赖安装、示例数据下载、推理、以及原视频与稳定视频的简单稳定性指标对比并导出 CSV。每个代码块按顺序执行即可。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXB4gNICwnN"
      },
      "source": [
        "## 环境要求\n",
        "- 在 Colab 菜单选择：Runtime → Change runtime type → Hardware accelerator 选 GPU。\n",
        "- 每个代码块都是独立单元，按顺序运行。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-rT3DpiCwnN",
        "outputId": "d9d6562a-7832-4ba3-ae5b-3eaa3bab08b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-stabilization'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 78 (delta 8), reused 47 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (78/78), 39.71 MiB | 25.69 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "/content/deep-stabilization/dvs\n",
            "/content/deep-stabilization/dvs\n",
            "checkpoint  flownet2\t\t       loss.py\t   requirements.txt\n",
            "conf\t    gyro\t\t       metrics.py  train.py\n",
            "data\t    inference.py\t       model.py    util.py\n",
            "dataset.py  load_frame_sensor_data.py  printer.py  warp\n"
          ]
        }
      ],
      "source": [
        "# 克隆仓库并进入 dvs 目录\n",
        "!git clone --depth 1 https://github.com/googleinterns/deep-stabilization.git\n",
        "%cd deep-stabilization/dvs\n",
        "\n",
        "!pwd\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDN8-l0MCwnO",
        "outputId": "73620440-980d-4295-9c8d-3c257588c004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpeg (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python >=3.8,<3.12; 1.10.0rc1 Requires-Python >=3.8,<3.12; 1.10.0rc2 Requires-Python >=3.8,<3.12; 1.10.1 Requires-Python >=3.8,<3.12; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.17.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.10.1\u001b[0m\u001b[31m\n",
            "\u001b[0mPyTorch: 2.9.0+cu126 CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# 安装依赖（避开旧版本兼容问题）\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install colorama ffmpeg imageio matplotlib pytz PyYAML tensorboardX tqdm pillow pandas\n",
        "!pip -q install opencv-python-headless scikit-image\n",
        "# Py3.12 上 1.10.1 没有 wheel，使用兼容的 1.11.x\n",
        "!pip -q install \"scipy==1.11.4\"\n",
        "\n",
        "import torch, torchvision, sys, os\n",
        "print('PyTorch:', torch.__version__, 'CUDA available:', torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlVjqta_CwnO",
        "outputId": "11678410-0806-467c-b5a2-1266ac8ad32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1PpF3-6BbQKy9fldjIfwa5AlbtQflx3sG\n",
            "From (redirected): https://drive.google.com/uc?id=1PpF3-6BbQKy9fldjIfwa5AlbtQflx3sG&confirm=t&uuid=07b1c4d0-3dcd-4f0a-a66b-f0cd7dba2407\n",
            "To: /content/deep-stabilization/dvs/sample_video.zip\n",
            "100% 914M/914M [00:13<00:00, 68.4MB/s]\n",
            "s_114_outdoor_running_trail_daytime\n"
          ]
        }
      ],
      "source": [
        "# 下载示例数据（作者提供的 sample video）\n",
        "!pip -q install gdown\n",
        "\n",
        "!rm -rf video sample_video.zip\n",
        "!gdown --fuzzy -O sample_video.zip \"https://drive.google.com/file/d/1PpF3-6BbQKy9fldjIfwa5AlbtQflx3sG/view?usp=sharing\"\n",
        "!unzip -q sample_video.zip\n",
        "\n",
        "!ls video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 检查/准备 5 个待推理序列\n",
        "import os, shutil\n",
        "\n",
        "DESIRED_VIDEO_COUNT = 5\n",
        "seq_dirs = [d for d in sorted(os.listdir(\"./video\")) if os.path.isdir(os.path.join(\"video\", d))]\n",
        "print(f\"当前检测到 {len(seq_dirs)} 个序列:\", seq_dirs)\n",
        "\n",
        "if len(seq_dirs) < DESIRED_VIDEO_COUNT:\n",
        "    print(f\"⚠️ 还差 {DESIRED_VIDEO_COUNT - len(seq_dirs)} 个序列。请将包含原视频及传感器/光流文件的文件夹解压到 ./video 下（结构与示例序列一致）。\")\n",
        "    print(\"如需要，可启用下方的重复样本开关，仅用于验证流程：\")\n",
        "\n",
        "ALLOW_DUPLICATE_SAMPLE = False\n",
        "if len(seq_dirs) < DESIRED_VIDEO_COUNT and ALLOW_DUPLICATE_SAMPLE and seq_dirs:\n",
        "    sample_src = os.path.join(\"video\", seq_dirs[0])\n",
        "    while len(seq_dirs) < DESIRED_VIDEO_COUNT:\n",
        "        dup_name = f\"{seq_dirs[0]}_dup{len(seq_dirs)}\"\n",
        "        dup_dst = os.path.join(\"video\", dup_name)\n",
        "        if os.path.exists(dup_dst):\n",
        "            seq_dirs.append(dup_name)\n",
        "            continue\n",
        "        shutil.copytree(sample_src, dup_dst)\n",
        "        seq_dirs.append(dup_name)\n",
        "        print(\"已复制示例序列到\", dup_dst)\n",
        "print(\"最终序列列表:\", seq_dirs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qccm3vdCwnO",
        "outputId": "31c27303-030a-4388-856d-8f5480093cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/deep-stabilization/dvs/load_frame_sensor_data.py\", line 118, in <module>\n",
            "    main(args = args)\n",
            "  File \"/content/deep-stabilization/dvs/load_frame_sensor_data.py\", line 100, in main\n",
            "    cf = yaml.load(open(config_file, 'r'))\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: load() missing 1 required positional argument: 'Loader'\n"
          ]
        }
      ],
      "source": [
        "# （可选）数据可视化/预处理示例：生成传感器曲线等\n",
        "# 如果不需要可跳过此单元\n",
        "!python load_frame_sensor_data.py --config ./conf/stabilzation.yaml --dir_path ./video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODkcpfF3CwnO",
        "outputId": "9bc9662f-c7d6-4a2f-9527-aa20e49a22b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/deep-stabilization/dvs/inference.py\", line 217, in <module>\n",
            "    main(args = args)\n",
            "  File \"/content/deep-stabilization/dvs/inference.py\", line 190, in main\n",
            "    cf = yaml.load(open(config_file, 'r'))\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: load() missing 1 required positional argument: 'Loader'\n",
            "ls: cannot access 'test/stabilzation': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# 运行推理（使用仓库自带的预训练模型）\n",
        "# 默认会读取 ./checkpoint/stabilzation/stabilzation_last.checkpoint\n",
        "!python inference.py --config ./conf/stabilzation.yaml --dir_path ./video\n",
        "\n",
        "# 查看输出文件（稳定后视频和曲线）\n",
        "!ls test/stabilzation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEvgrnvgCwnP"
      },
      "source": [
        "## 计算稳定性指标（原视频 vs 稳定视频）\n",
        "新增更通用、可比较的指标，并对多视频做统计：\n",
        "- `mean_flow_*`/`std_flow_*`：逐帧 Farneback 光流模长的均值/标准差。\n",
        "- `flow_p95_*`/`flow_iqr_*`：逐帧光流模长分布的 95 分位与四分位距，衡量抖动尾部与稳定性。\n",
        "- `flow_jitter_std_*`：逐帧光流中位数的一阶差分标准差，反映抖动突变。\n",
        "- `temporal_mse_*`：相邻帧像素 MSE，越小越平滑。\n",
        "- `temporal_ssim_*`：相邻帧 SSIM，越大越平滑。\n",
        "- `stability_gain`：`(orig_mean_flow - stab_mean_flow) / orig_mean_flow`。\n",
        "结果会写到 `test/stabilzation/stabilization_metrics.csv`，并生成跨 5 段视频的统计 `stabilization_metrics_summary.csv`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwHWAKwNCwnP",
        "outputId": "cf58c281-8be0-4e4f-dfa1-70addeda9d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "跳过，未找到稳定视频: ./test/stabilzation/s_114_outdoor_running_trail_daytime_stab.mp4\n",
            "未生成任何指标\n"
          ]
        }
      ],
      "source": [
        "import os, cv2, numpy as np, pandas as pd\n",
        "from typing import List, Tuple\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "\n",
        "def load_video(path: str, max_frames: int = None, resize: float = 1.0) -> Tuple[List[np.ndarray], float, Tuple[int, int]]:\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if resize != 1.0:\n",
        "            frame = cv2.resize(frame, (0, 0), fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n",
        "        frames.append(frame)\n",
        "        if max_frames and len(frames) >= max_frames:\n",
        "            break\n",
        "    cap.release()\n",
        "    return frames, fps, (frames[0].shape[1], frames[0].shape[0]) if frames else (0, 0)\n",
        "\n",
        "\n",
        "def flow_stats(frames: List[np.ndarray]):\n",
        "    med_per_frame = []\n",
        "    for i in range(len(frames) - 1):\n",
        "        g1 = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
        "        g2 = cv2.cvtColor(frames[i + 1], cv2.COLOR_BGR2GRAY)\n",
        "        flow = cv2.calcOpticalFlowFarneback(g1, g2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "        mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "        med_per_frame.append(np.median(mag))\n",
        "    if len(med_per_frame) == 0:\n",
        "        return {\n",
        "            \"mean\": 0.0,\n",
        "            \"std\": 0.0,\n",
        "            \"p95\": 0.0,\n",
        "            \"iqr\": 0.0,\n",
        "            \"jitter_std\": 0.0,\n",
        "        }\n",
        "    arr = np.array(med_per_frame)\n",
        "    diffs = np.diff(arr)\n",
        "    return {\n",
        "        \"mean\": float(np.mean(arr)),\n",
        "        \"std\": float(np.std(arr)),\n",
        "        \"p95\": float(np.percentile(arr, 95)),\n",
        "        \"iqr\": float(np.percentile(arr, 75) - np.percentile(arr, 25)),\n",
        "        \"jitter_std\": float(np.std(diffs)) if len(diffs) > 0 else 0.0,\n",
        "    }\n",
        "\n",
        "\n",
        "def temporal_mse(frames: List[np.ndarray]) -> float:\n",
        "    vals = []\n",
        "    for i in range(len(frames) - 1):\n",
        "        diff = frames[i].astype(np.float32) - frames[i + 1].astype(np.float32)\n",
        "        vals.append(np.mean(diff ** 2))\n",
        "    return float(np.mean(vals)) if vals else 0.0\n",
        "\n",
        "\n",
        "def temporal_ssim(frames: List[np.ndarray]) -> float:\n",
        "    vals = []\n",
        "    for i in range(len(frames) - 1):\n",
        "        g1 = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
        "        g2 = cv2.cvtColor(frames[i + 1], cv2.COLOR_BGR2GRAY)\n",
        "        score = ssim(g1, g2, data_range=255)\n",
        "        vals.append(score)\n",
        "    return float(np.mean(vals)) if vals else 0.0\n",
        "\n",
        "\n",
        "def compare_one(orig_path: str, stab_path: str, max_frames: int = 600, resize: float = 0.5):\n",
        "    orig_frames, fps_o, _ = load_video(orig_path, max_frames=max_frames, resize=resize)\n",
        "    stab_frames, fps_s, _ = load_video(stab_path, max_frames=max_frames, resize=resize)\n",
        "    n = min(len(orig_frames), len(stab_frames))\n",
        "    if n < 2:\n",
        "        raise ValueError(f\"帧数不足，orig={len(orig_frames)}, stab={len(stab_frames)}\")\n",
        "    orig_frames = orig_frames[:n]\n",
        "    stab_frames = stab_frames[:n]\n",
        "\n",
        "    o_flow = flow_stats(orig_frames)\n",
        "    s_flow = flow_stats(stab_frames)\n",
        "    o_mse = temporal_mse(orig_frames)\n",
        "    s_mse = temporal_mse(stab_frames)\n",
        "    o_ssim = temporal_ssim(orig_frames)\n",
        "    s_ssim = temporal_ssim(stab_frames)\n",
        "\n",
        "    return {\n",
        "        \"orig_video\": orig_path,\n",
        "        \"stab_video\": stab_path,\n",
        "        \"num_frames_used\": n,\n",
        "        \"fps_orig\": fps_o,\n",
        "        \"fps_stab\": fps_s,\n",
        "        \"mean_flow_orig\": o_flow[\"mean\"],\n",
        "        \"mean_flow_stab\": s_flow[\"mean\"],\n",
        "        \"std_flow_orig\": o_flow[\"std\"],\n",
        "        \"std_flow_stab\": s_flow[\"std\"],\n",
        "        \"flow_p95_orig\": o_flow[\"p95\"],\n",
        "        \"flow_p95_stab\": s_flow[\"p95\"],\n",
        "        \"flow_iqr_orig\": o_flow[\"iqr\"],\n",
        "        \"flow_iqr_stab\": s_flow[\"iqr\"],\n",
        "        \"flow_jitter_std_orig\": o_flow[\"jitter_std\"],\n",
        "        \"flow_jitter_std_stab\": s_flow[\"jitter_std\"],\n",
        "        \"temporal_mse_orig\": o_mse,\n",
        "        \"temporal_mse_stab\": s_mse,\n",
        "        \"temporal_ssim_orig\": o_ssim,\n",
        "        \"temporal_ssim_stab\": s_ssim,\n",
        "        \"stability_gain\": 0.0 if o_flow[\"mean\"] == 0 else (o_flow[\"mean\"] - s_flow[\"mean\"]) / o_flow[\"mean\"],\n",
        "    }\n",
        "\n",
        "\n",
        "def run_all(video_root: str = \"./video\", stab_root: str = \"./test/stabilzation\", desired_count: int = 5):\n",
        "    records = []\n",
        "    seq_list = [d for d in sorted(os.listdir(video_root)) if os.path.isdir(os.path.join(video_root, d))]\n",
        "    if desired_count is not None:\n",
        "        if len(seq_list) < desired_count:\n",
        "            print(f\"⚠️ 当前只有 {len(seq_list)} 个序列，少于期望的 {desired_count} 个，请补齐后重跑以避免偶然性。\")\n",
        "        seq_list = seq_list[:desired_count]\n",
        "    for seq in seq_list:\n",
        "        seq_dir = os.path.join(video_root, seq)\n",
        "        mp4s = [f for f in os.listdir(seq_dir) if f.lower().endswith(\".mp4\") and \"gimbal\" not in f.lower()]\n",
        "        if not mp4s:\n",
        "            print(f\"跳过 {seq}，未找到 mp4\")\n",
        "            continue\n",
        "        mp4 = mp4s[0]\n",
        "        orig_path = os.path.join(seq_dir, mp4)\n",
        "        stab_path = os.path.join(stab_root, f\"{seq}_stab.mp4\")\n",
        "        if not os.path.exists(stab_path):\n",
        "            print(f\"跳过，未找到稳定视频: {stab_path}\")\n",
        "            continue\n",
        "        try:\n",
        "            rec = compare_one(orig_path, stab_path)\n",
        "            rec[\"seq\"] = seq\n",
        "            records.append(rec)\n",
        "            print(f\"done: {seq}\")\n",
        "        except Exception as e:\n",
        "            print(f\"失败 {seq}: {e}\")\n",
        "    if not records:\n",
        "        print(\"未生成任何指标\")\n",
        "        return None, None\n",
        "    df = pd.DataFrame(records)\n",
        "    out_path = os.path.join(stab_root, \"stabilization_metrics.csv\")\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(\"保存:\", out_path)\n",
        "\n",
        "    metric_cols = [c for c in df.columns if c not in {\"seq\", \"orig_video\", \"stab_video\"}]\n",
        "    summary_df = df[metric_cols].agg([\"mean\", \"std\", \"min\", \"max\"])\n",
        "    summary_path = os.path.join(stab_root, \"stabilization_metrics_summary.csv\")\n",
        "    summary_df.to_csv(summary_path)\n",
        "    print(\"保存统计:\", summary_path)\n",
        "    return df, summary_df\n",
        "\n",
        "\n",
        "# 运行指标计算\n",
        "metrics_df, metrics_summary = run_all()\n",
        "metrics_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "h5b7MYhVCwnQ",
        "outputId": "e15a384f-ab61-48d4-d6ad-410195e92354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Inference: 1/1\n",
            "------Load Pretrined Model--------\n",
            "./checkpoint/stabilzation/stabilzation_last.checkpoint\n",
            "-----------Load Dataset----------\n",
            "./video/s_114_outdoor_running_trail_daytime\n",
            "frame: (511, 7)    gyro: (3746, 5)    ois: (3916, 3)    flo_path: 470    flo_shape: (270, 480, 2)    \n",
            "Fininsh Load data\n",
            "/content/deep-stabilization/dvs/loss.py:86: UserWarning: `nn.functional.upsample_bilinear` is deprecated. Use `nn.functional.interpolate` instead.\n",
            "  grid_t = torch.nn.functional.upsample_bilinear(grid_t, size = (h, w)) # [B,C(xy),H,W]\n",
            "/content/deep-stabilization/dvs/loss.py:89: UserWarning: `nn.functional.upsample_bilinear` is deprecated. Use `nn.functional.interpolate` instead.\n",
            "  grid_t_1 = torch.nn.functional.upsample_bilinear(grid_t_1, size = (h, w)) # [B,C(xy),H,W]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:5100: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "Step: 100/470\n",
            "Step: 200/470\n",
            "Step: 300/470\n",
            "Step: 400/470\n",
            "\n",
            "Loss: follow, angle, smooth, c2_smooth, undefine, optical\n",
            "[8.4722955e-03 1.9884116e-03 1.2372581e-05 1.1924115e-05 1.0951313e-03\n",
            " 8.4513842e-05] \n",
            "\n",
            "(471, 5)\n",
            "Time_used: 0.8719 minutes\n",
            "------Start Warping Video--------\n",
            "------Start Visual Result--------\n",
            "(1080, 1920, 3)\n",
            "Video length:  470\n",
            "Frame: 0/470\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:5100: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "Frame: 100/470\n",
            "Frame: 200/470\n",
            "Frame: 300/470\n",
            "Frame: 400/470\n",
            "正在重新计算指标...\n",
            "done: s_114_outdoor_running_trail_daytime\n",
            "保存: ./test/stabilzation/stabilization_metrics.csv\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_43df5090-5f04-4025-9ce8-52d153c44384\", \"results_stabilzation.zip\", 89674606)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 修复依赖问题：将 yaml.load 替换为 yaml.safe_load（防止 Loader 报错）\n",
        "!sed -i \"s/yaml.load(open(config_file, 'r'))/yaml.safe_load(open(config_file, 'r'))/g\" inference.py load_frame_sensor_data.py\n",
        "\n",
        "# 创建日志目录（修复 FileNotFoundError）\n",
        "!mkdir -p log\n",
        "\n",
        "# 重新运行推理（确保生成 test/stabilzation 目录）\n",
        "!python inference.py --config ./conf/stabilzation.yaml --dir_path ./video\n",
        "\n",
        "# 重新计算指标（如果 run_all 函数已定义）\n",
        "import os\n",
        "try:\n",
        "    if 'run_all' in globals():\n",
        "        print(\"正在重新计算指标...\")\n",
        "        metrics_df, metrics_summary = run_all(desired_count=5)\n",
        "        if metrics_df is not None:\n",
        "            display(metrics_df)\n",
        "        if metrics_summary is not None:\n",
        "            print(\"跨视频统计：\")\n",
        "            display(metrics_summary)\n",
        "    else:\n",
        "        print(\"run_all 函数未定义，跳过指标计算。请确保已运行上一个代码块。\")\n",
        "except Exception as e:\n",
        "    print(f\"指标计算出错: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# 打包下载推理结果和指标\n",
        "!zip -qr results_stabilzation.zip test/stabilzation\n",
        "from google.colab import files\n",
        "if os.path.exists('results_stabilzation.zip'):\n",
        "    files.download('results_stabilzation.zip')\n",
        "else:\n",
        "    print(\"错误：无法找到 results_stabilzation.zip，请检查推理步骤是否成功。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "从 notebook 的推理日志可知示例视频（s_114_outdoor_running_trail_daytime）的主要规格：\n",
        "分辨率：1920 x 1080（日志里的 (1080, 1920, 3)）。\n",
        "帧数：约 470 帧（日志显示 Video length: 470）。\n",
        "光流帧尺寸：270 x 480 x 2（用于模型的 flo 输入）。\n",
        "gyro/ois/帧对齐后数据行数：frame: (511, 7) gyro: (3746, 5) ois: (3916, 3)（输入元数据）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查看视频 FPS / 帧数 / 分辨率\n",
        "import os, cv2, pandas as pd\n",
        "\n",
        "def list_video_fps(video_root: str = \"./video\"):\n",
        "    rows = []\n",
        "    for seq in sorted(os.listdir(video_root)):\n",
        "        seq_dir = os.path.join(video_root, seq)\n",
        "        if not os.path.isdir(seq_dir):\n",
        "            continue\n",
        "        mp4s = [f for f in os.listdir(seq_dir) if f.lower().endswith(\".mp4\")]\n",
        "        for mp4 in mp4s:\n",
        "            path = os.path.join(seq_dir, mp4)\n",
        "            cap = cv2.VideoCapture(path)\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "            w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "            h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "            cap.release()\n",
        "            rows.append({\n",
        "                \"seq\": seq,\n",
        "                \"file\": mp4,\n",
        "                \"fps\": fps,\n",
        "                \"frames\": frames,\n",
        "                \"width\": w,\n",
        "                \"height\": h,\n",
        "            })\n",
        "    if rows:\n",
        "        df = pd.DataFrame(rows)\n",
        "        display(df)\n",
        "    else:\n",
        "        print(\"未找到 mp4 文件，请先解压/放置到 ./video\")\n",
        "\n",
        "list_video_fps()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "d05cd7a9",
        "outputId": "4a6bdef4-700b-4a88-e824-c37db808f90a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_metrics\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"orig_video\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"./video/s_114_outdoor_running_trail_daytime/ControlCam_20200930_104820.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stab_video\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"./test/stabilzation/s_114_outdoor_running_trail_daytime_stab.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_frames_used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 470,\n        \"max\": 470,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          470\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps_orig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 30.020507836629136,\n        \"max\": 30.020507836629136,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30.020507836629136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps_stab\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 30.02,\n        \"max\": 30.02,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_flow_orig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 9.107696533203123,\n        \"max\": 9.107696533203123,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9.107696533203123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_flow_stab\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.2885701656341557,\n        \"max\": 3.2885701656341557,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.2885701656341557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_flow_orig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 7.322388172149658,\n        \"max\": 7.322388172149658,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.322388172149658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_flow_stab\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.5508973598480225,\n        \"max\": 1.5508973598480225,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.5508973598480225\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temporal_mse_orig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1093.572265625,\n        \"max\": 1093.572265625,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1093.572265625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temporal_mse_stab\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1028.5350341796875,\n        \"max\": 1028.5350341796875,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1028.5350341796875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stability_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6389240513619108,\n        \"max\": 0.6389240513619108,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6389240513619108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seq\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"s_114_outdoor_running_trail_daytime\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_metrics"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-04870672-089e-4d9c-9ca1-237cec8d5990\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig_video</th>\n",
              "      <th>stab_video</th>\n",
              "      <th>num_frames_used</th>\n",
              "      <th>fps_orig</th>\n",
              "      <th>fps_stab</th>\n",
              "      <th>mean_flow_orig</th>\n",
              "      <th>mean_flow_stab</th>\n",
              "      <th>std_flow_orig</th>\n",
              "      <th>std_flow_stab</th>\n",
              "      <th>temporal_mse_orig</th>\n",
              "      <th>temporal_mse_stab</th>\n",
              "      <th>stability_gain</th>\n",
              "      <th>seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./video/s_114_outdoor_running_trail_daytime/Co...</td>\n",
              "      <td>./test/stabilzation/s_114_outdoor_running_trai...</td>\n",
              "      <td>470</td>\n",
              "      <td>30.020508</td>\n",
              "      <td>30.02</td>\n",
              "      <td>9.107697</td>\n",
              "      <td>3.28857</td>\n",
              "      <td>7.322388</td>\n",
              "      <td>1.550897</td>\n",
              "      <td>1093.572266</td>\n",
              "      <td>1028.535034</td>\n",
              "      <td>0.638924</td>\n",
              "      <td>s_114_outdoor_running_trail_daytime</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04870672-089e-4d9c-9ca1-237cec8d5990')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04870672-089e-4d9c-9ca1-237cec8d5990 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04870672-089e-4d9c-9ca1-237cec8d5990');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_365088a6-e677-4664-8f4d-902126777ffd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metrics')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_365088a6-e677-4664-8f4d-902126777ffd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metrics');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          orig_video                                         stab_video  num_frames_used   fps_orig  fps_stab  mean_flow_orig  mean_flow_stab  std_flow_orig  std_flow_stab  temporal_mse_orig  temporal_mse_stab  stability_gain                                  seq\n",
              "0  ./video/s_114_outdoor_running_trail_daytime/Co...  ./test/stabilzation/s_114_outdoor_running_trai...              470  30.020508     30.02        9.107697         3.28857       7.322388       1.550897        1093.572266        1028.535034        0.638924  s_114_outdoor_running_trail_daytime"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 读取生成的指标 CSV 文件\n",
        "csv_path = './test/stabilzation/stabilization_metrics.csv'\n",
        "summary_path = './test/stabilzation/stabilization_metrics_summary.csv'\n",
        "if os.path.exists(csv_path):\n",
        "    df_metrics = pd.read_csv(csv_path)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.width', 1000)\n",
        "    display(df_metrics)\n",
        "else:\n",
        "    print(\"未找到指标文件，请确认上一步是否执行成功。\")\n",
        "\n",
        "if os.path.exists(summary_path):\n",
        "    df_summary = pd.read_csv(summary_path, index_col=0)\n",
        "    print(\"跨视频统计：\")\n",
        "    display(df_summary)\n",
        "else:\n",
        "    print(\"未找到统计文件，请确认 run_all 已运行。\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
